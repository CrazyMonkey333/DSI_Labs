{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 2: Predicting Chronic Kidney Disease in Patients\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus on steps exploring data, building models and evaluating the models we build.\n",
    "\n",
    "There are three links you may find important:\n",
    "- [A set of chronic kidney disease (CKD) data and other biological factors](./chronic_kidney_disease_full.csv).\n",
    "- [The CKD data dictionary](./chronic_kidney_disease_header.txt).\n",
    "- [An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD](./chronic_kidney_disease.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Suppose you're working for Mayo Clinic, widely recognized to be the top hospital in the United States. In your work, you've overheard nurses and doctors discuss test results, then arrive at a conclusion as to whether or not someone has developed a particular disease or condition. For example, you might overhear something like:\n",
    "\n",
    "> **Nurse**: Male 57 year-old patient presents with severe chest pain. FDP _(short for fibrin degradation product)_ was elevated at 13. We did an echo _(echocardiogram)_ and it was inconclusive.\n",
    "\n",
    "> **Doctor**: What was his interarm BP? _(blood pressure)_\n",
    "\n",
    "> **Nurse**: Systolic was 140 on the right; 110 on the left.\n",
    "\n",
    "> **Doctor**: Dammit, it's an aortic dissection! Get to the OR _(operating room)_ now!\n",
    "\n",
    "> _(intense music playing)_\n",
    "\n",
    "In this fictitious but [Shonda Rhimes-esque](https://en.wikipedia.org/wiki/Shonda_Rhimes#Grey's_Anatomy,_Private_Practice,_Scandal_and_other_projects_with_ABC) scenario, you might imagine the doctor going through a series of steps like a [flowchart](https://en.wikipedia.org/wiki/Flowchart), or a series of if-this-then-that steps to diagnose a patient. The first steps made the doctor ask what the interarm blood pressure was. Because interarm blood pressure took on the values it took on, the doctor diagnosed the patient with an aortic dissection.\n",
    "\n",
    "Your goal, as a research biostatistical data scientist at the nation's top hospital, is to develop a medical test that can improve upon our current diagnosis system for [chronic kidney disease (CKD)](https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521).\n",
    "\n",
    "**Real-world problem**: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Obtain the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...   pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd = pd.read_csv('./chronic_kidney_disease_full.csv')\n",
    "ckd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the data dictionary. What are a few features or relationships you might be interested in checking out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "I'd like to see how the classes are balanced first and formost. \n",
    "\n",
    "Then, I'd like to find a way to take care of the null values in a non destructive manner, and identify if anything is missing so much so that it may not be usefull.  \n",
    "\n",
    "Check the distribution of variables and identify if features have importance or are simply non predictive.\n",
    "\n",
    "Next, I'll check for correlations between ckd and the other features to identify what may be important or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 3. How much of the data is missing from each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.isnull().sum() # It looks like every column is missing something except for our target ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Suppose that I dropped every row that contained at least one missing value. (In the context of analysis with missing data, we call this a \"complete case analysis,\" because we keep only the complete cases!) How many rows would remain in our dataframe? What are at least two downsides to doing this?\n",
    "\n",
    "> There's a good visual on slide 15 of [this deck](https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf) that shows what a complete case analysis looks like if you're interested.  \n",
    "**Note:** You can clean your data below in step 4 when building a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_of_ckd = ckd.dropna()\n",
    "copy_of_ckd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.605"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(400-158)/400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "This would be terrible. We would lose a lot of our data! In fact we go from 400 to 158 rows. This is a loss of over 60% of the data and it is already a small dataset. (1. we severly limit the amount of data we use and we throw out a lot of potentially usefull information. 2.NA could  mean something in many of these columns and discarding them may be removing an entire features usefullness.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Thinking critically about how our data were gathered, it's likely that these records were gathered by doctors and nurses. Brainstorm three potential areas (in addition to the missing data we've already discussed) where this data might be inaccurate or imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Human error can be a factor as unfortunate as that can be, patients could be mixed up or the data incorectly recorded. \n",
    "\n",
    "Some of the data may be subjective if it is nominal and one doctor/patient may have different view point of something such as appetite, or if something is abnormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 6. Suppose that I want to construct a \"model\" where no person who has CKD will ever be told that they do not have CKD. What (very simple, no machine learning needed) model can I create that will never tell a person with CKD that they do not have CKD?\n",
    "\n",
    "> Hint: Don't think about `statsmodels` or `scikit-learn` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We could tell everyone that they have it, but that's a pretty bad practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. In problem 6, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We optimized sensitivity so we had no false negatives. A false negative would be a actual positive case that was incorrectly predicted and that would be bad in this medical instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Thinking ethically, what is at least one disadvantage to the model you described in problem 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Telling everyone they have CKD is a disadvantage because the model is no good at determining what actually makes a difference in if someone has CKD. It also can create a lot of anxiety in patients in which they may lose faith in the medical process if everyone is incorrectly dignosed. May cost a lot of money to treat CKD that is unnessesarily spent in the case of false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Suppose that I want to construct a \"model\" where a person who does not have CKD will ever be told that they do have CKD. What (very simple, no machine learning needed) model can I create that will accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Tell everyone that they do not have CKD. Also a terrible option but fufills the above task of no false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. In problem 9, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We optimized the specificity by minimizing the false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Thinking ethically, what is at least one disadvantage to the model you described in problem 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: This is unethical because now we will have a lot of false negatives and many people that have CKD will go undiagnosed. If CKD is a serious health concern it will be disasterous for many people's livelyhood. I'd say this is even worse than diagnosing everyone because many people will be at risk and potentially die! Also the model is pretty much pointless because it does no detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Construct a logistic regression model in `sklearn` predicting class from the other variables. You may scale, select/drop, and engineer features as you wish - build a good model! Make sure, however, that you include at least one categorical/dummy feature and at least one quantitative feature.\n",
    "\n",
    "> Hint 1: Remember to do a train/test split!  \n",
    "> Hint 2: This will require data cleaning first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...   pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    250\n",
       "0    150\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd['target'] = [1 if i == 'ckd' else 0 for i in ckd['class']]\n",
    "ckd.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the target variable as a binary numerical. Next let us create an interaction term with potentially correlated terms. \n",
    "1. Pus cell and Pus Cell Clumps\n",
    "2. White Blood Cell Count and Red Blood Cell Count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['pc_pcc_interaction'] = [1 if ckd.loc[i, 'pc'] == 'abnormal'\n",
    "                             and ckd.loc[i, 'pcc'] == 'present'\n",
    "                             else 0 for i in range(len(ckd['pc']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['wbcc_rbcc_interaction'] = ckd['wbcc'] * ckd['rbcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions are now created in the dataframe. Now we must dummify all the nominal parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      float64\n",
       "bp                       float64\n",
       "sg                       float64\n",
       "al                       float64\n",
       "su                       float64\n",
       "rbc                       object\n",
       "pc                        object\n",
       "pcc                       object\n",
       "ba                        object\n",
       "bgr                      float64\n",
       "bu                       float64\n",
       "sc                       float64\n",
       "sod                      float64\n",
       "pot                      float64\n",
       "hemo                     float64\n",
       "pcv                      float64\n",
       "wbcc                     float64\n",
       "rbcc                     float64\n",
       "htn                       object\n",
       "dm                        object\n",
       "cad                       object\n",
       "appet                     object\n",
       "pe                        object\n",
       "ane                       object\n",
       "class                     object\n",
       "target                     int64\n",
       "pc_pcc_interaction         int64\n",
       "wbcc_rbcc_interaction    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>48.000</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>80.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>70.000</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sg</th>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bgr</th>\n",
       "      <td>121.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423.00</td>\n",
       "      <td>117.000</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bu</th>\n",
       "      <td>36.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>56.000</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.800</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemo</th>\n",
       "      <td>15.40</td>\n",
       "      <td>11.30</td>\n",
       "      <td>9.60</td>\n",
       "      <td>11.200</td>\n",
       "      <td>11.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcv</th>\n",
       "      <td>44.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>32.000</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbcc</th>\n",
       "      <td>7800.00</td>\n",
       "      <td>6000.00</td>\n",
       "      <td>7500.00</td>\n",
       "      <td>6700.000</td>\n",
       "      <td>7300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbcc</th>\n",
       "      <td>5.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.900</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc_pcc_interaction</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbcc_rbcc_interaction</th>\n",
       "      <td>40560.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26130.000</td>\n",
       "      <td>33580.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbc_normal</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc_normal</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_present</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba_present</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>htn_yes</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm_yes</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cad_yes</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appet_poor</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_yes</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ane_yes</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_notckd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0        1        2          3         4\n",
       "age                       48.00     7.00    62.00     48.000     51.00\n",
       "bp                        80.00    50.00    80.00     70.000     80.00\n",
       "sg                         1.02     1.02     1.01      1.005      1.01\n",
       "al                         1.00     4.00     2.00      4.000      2.00\n",
       "su                         0.00     0.00     3.00      0.000      0.00\n",
       "bgr                      121.00      NaN   423.00    117.000    106.00\n",
       "bu                        36.00    18.00    53.00     56.000     26.00\n",
       "sc                         1.20     0.80     1.80      3.800      1.40\n",
       "sod                         NaN      NaN      NaN    111.000       NaN\n",
       "pot                         NaN      NaN      NaN      2.500       NaN\n",
       "hemo                      15.40    11.30     9.60     11.200     11.60\n",
       "pcv                       44.00    38.00    31.00     32.000     35.00\n",
       "wbcc                    7800.00  6000.00  7500.00   6700.000   7300.00\n",
       "rbcc                       5.20      NaN      NaN      3.900      4.60\n",
       "target                     1.00     1.00     1.00      1.000      1.00\n",
       "pc_pcc_interaction         0.00     0.00     0.00      1.000      0.00\n",
       "wbcc_rbcc_interaction  40560.00      NaN      NaN  26130.000  33580.00\n",
       "rbc_normal                 0.00     0.00     1.00      1.000      1.00\n",
       "pc_normal                  1.00     1.00     1.00      0.000      1.00\n",
       "pcc_present                0.00     0.00     0.00      1.000      0.00\n",
       "ba_present                 0.00     0.00     0.00      0.000      0.00\n",
       "htn_yes                    1.00     0.00     0.00      1.000      0.00\n",
       "dm_yes                     1.00     0.00     1.00      0.000      0.00\n",
       "cad_yes                    0.00     0.00     0.00      0.000      0.00\n",
       "appet_poor                 0.00     0.00     1.00      1.000      0.00\n",
       "pe_yes                     0.00     0.00     0.00      1.000      0.00\n",
       "ane_yes                    0.00     0.00     1.00      1.000      0.00\n",
       "class_notckd               0.00     0.00     0.00      0.000      0.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd_dummified =  pd.get_dummies(ckd, drop_first=True)\n",
    "ckd_dummified.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_dummified.drop(columns=['class_notckd'], inplace=True)\n",
    "# Droping the unessesary target variable (already got a target one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL VALUES ARE PREVENTING THE MODEL FROM GOING FORWARD.\n",
    "GOING TO FILL ALL NULLS WITH THE MEAN OF THEIR RESPECTIVE COLUMN. \n",
    "WARNING: NOT GOOD PRACTICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ckd_dummified.columns:\n",
    "    ckd_dummified[str(col)].fillna( ckd_dummified[str(col)].mean(), \n",
    "                                  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      0\n",
       "bp                       0\n",
       "sg                       0\n",
       "al                       0\n",
       "su                       0\n",
       "bgr                      0\n",
       "bu                       0\n",
       "sc                       0\n",
       "sod                      0\n",
       "pot                      0\n",
       "hemo                     0\n",
       "pcv                      0\n",
       "wbcc                     0\n",
       "rbcc                     0\n",
       "target                   0\n",
       "pc_pcc_interaction       0\n",
       "wbcc_rbcc_interaction    0\n",
       "rbc_normal               0\n",
       "pc_normal                0\n",
       "pcc_present              0\n",
       "ba_present               0\n",
       "htn_yes                  0\n",
       "dm_yes                   0\n",
       "cad_yes                  0\n",
       "appet_poor               0\n",
       "pe_yes                   0\n",
       "ane_yes                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd_dummified.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay We have everything we need, ALl the parameters are included and accounted for. Next we should create a Standard scaler and train-test-split this data set up. Lets do it! \n",
    "\n",
    "Important to note that regularization depends on the scale of the features so we must scale it! I do it out of good habbit but its important whenever we do a l1 or l2 regularization. (LASSO and Ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler() # initializing the SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ckd_dummified.drop(columns=['target'])\n",
    "y = ckd_dummified['target']\n",
    "X_scaled = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                   test_size = 0.2, \n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay lets do a gridsearched model over Ridge and LASSO models, class weights as normal or balanced, and differing C values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear',\n",
    "                       max_iter = 1000, \n",
    "                       random_state=42)\n",
    "# We are testing l1 and l2 penalties in GridSearch.\n",
    "# The default solver 'lbfgs' only supports l2, \n",
    "# so we're switching to 'liblinear' instead.\n",
    "\n",
    "gs = GridSearchCV(estimator= lr,\n",
    "                 param_grid=params,\n",
    "                 scoring='recall', \n",
    "#recall is the metric we want to optimize\n",
    "                 cv = 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, penalty='l1', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l1',\n",
       " 'random_state': 42,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so our GS is great but we need the individual model to get the coefficients out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', \n",
    "                           max_iter=1000, \n",
    "                           C =10, \n",
    "                           class_weight='balanced',\n",
    "                           penalty = 'l2',\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
       "                   random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training score : 1.0\n",
      " Testing score : 0.9875\n"
     ]
    }
   ],
   "source": [
    "print(f' Training score : {logreg.score(X_train, y_train)}')\n",
    "print(f' Testing score : {logreg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Evaluate the model.\n",
    "\n",
    "### 13. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6193456906658227, 'age'),\n",
       " (2.8065286066714714, 'bp'),\n",
       " (0.126110072455217, 'sg'),\n",
       " (5.392977223606017, 'al'),\n",
       " (1.155574723495205, 'su'),\n",
       " (2.7790044913712975, 'bgr'),\n",
       " (0.5870156498526645, 'bu'),\n",
       " (2.6915443517513116, 'sc'),\n",
       " (0.4100884962566631, 'sod'),\n",
       " (1.0956095893501088, 'pot'),\n",
       " (0.11773108338147711, 'hemo'),\n",
       " (0.46952460819351005, 'pcv'),\n",
       " (1.1475899222243862, 'wbcc'),\n",
       " (0.336152793547641, 'rbcc'),\n",
       " (0.6997577378914587, 'pc_pcc_interaction'),\n",
       " (1.1894041216918751, 'wbcc_rbcc_interaction'),\n",
       " (0.08731394698702374, 'rbc_normal'),\n",
       " (1.1337111697131557, 'pc_normal'),\n",
       " (1.1416980172499411, 'pcc_present'),\n",
       " (0.9117166865418183, 'ba_present'),\n",
       " (2.5136264444978638, 'htn_yes'),\n",
       " (3.0913604913762533, 'dm_yes'),\n",
       " (0.6213955267963308, 'cad_yes'),\n",
       " (3.17930040323004, 'appet_poor'),\n",
       " (2.8884183083576094, 'pe_yes'),\n",
       " (0.9865048865020395, 'ane_yes')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(np.exp(logreg.coef_[0]) , X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As al-albumin increases by 1 unit (scaled however in this instance... We could rerun the model unscaled but it would lose accuracy.) the chances of getting a positive test result increase by 5.39. In this list it apears to be the strongest correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your categorical/dummy features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Pedal Edema (pe) has a 'scaled' 2.89 correlation. So when a patient \n",
    "has a yes on PE then there is a 2.89 increase in the chance that the\n",
    "patient has ckd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Despite being a relatively simple model, logistic regression is very widely used in the real world. Why do you think that's the case? Name at least two advantages to using logistic regression as a modeling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Logistical Regression allows the reader of the model to intrepret the coefficients and figure out the feature importance. \n",
    "\n",
    "Usually does not end up very overfit compared to other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Does it make sense to generate a confusion matrix on our training data or our test data? Why? Think about which data is used for model evaluation. Generate it on the proper data.\n",
    "\n",
    "> Hint: Once you've generated your predicted $y$ values and you have your observed $y$ values, then it will be easy to [generate a confusion matrix using sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes more sence to create a confusion matrix on our testing data because we want to determine effective our model is on new data, rather than on the data that created the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  1],\n",
       "       [ 0, 52]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 27\n",
      "False Positives: 1\n",
      "False Negatives: 0\n",
      "True Positives: 52\n"
     ]
    }
   ],
   "source": [
    "print('True Negatives: ' +str(tn) )\n",
    "print('False Positives: '+str(fp) )\n",
    "print('False Negatives: '+str(fn) )\n",
    "print('True Positives: ' +str(tp) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In this hospital case, we want to predict CKD. Do we want to optimize for sensitivity, specificity, or something else? Why? (If you don't think there's one clear answer, that's okay! There rarely is. Be sure to defend your conclusion!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "We want to optimize both if we can. Focusing only on sensitivity will give us to many false positives. Focusing only on specificity will give us false negatives and that will have ckd positives slip through and we cannot have that. So sensitivity is more important in this case but we should be working to optimize both. A combination of the sensitivity and specificity is called an f-1 score and we should optimize that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 (BONUS). Write a function that will create an ROC curve for you, then plot the ROC curve.\n",
    "\n",
    "Here's a strategy you might consider:\n",
    "1. In order to even begin, you'll need some fit model. Use your logistic regression model from problem 12.\n",
    "2. We want to look at all values of your \"threshold\" - that is, anything where .predict() gives you above your threshold falls in the \"positive class,\" and anything that is below your threshold falls in the \"negative class.\" Start the threshold at 0.\n",
    "3. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "4. Increment your threshold by some \"step.\" Maybe set your step to be 0.01, or even smaller.\n",
    "5. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "6. Repeat steps 3 and 4 until you get to the threshold of 1.\n",
    "7. Plot the values of sensitivity and 1 - specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from solution from Charlie.\n",
    "\n",
    "\n",
    "def roc(probas, true, step=0.01):\n",
    "    \"\"\"\n",
    "    probas should be a numpy array of predict_probas\n",
    "    true is a pandas series of true labels\n",
    "    step is the step size for checking thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    probas = probas[:,1]  # The output of predict_proba() is an array of the probabilities for every class, but we only want the probabilities for class 1\n",
    "    true = true.values    # We need to convert the class labels from a Pandas Series to a numpy array. We do this using the .values attribute\n",
    "    assert(len(probas) == len(true)) # We're making sure that our probabilities vector is the same length as our true class labesl vector\n",
    "    \n",
    "    TPRs = [] # Setting up empty list of True Positive Rate\n",
    "    FPRs = [] # Setting up empty list of False Positive Rate\n",
    "    \n",
    "    for i in np.arange(0.0,1.0,step): # np.arange allows us to use step sizes that are decimals\n",
    "        preds_class = probas > i # Numpy arrays have a feature called 'broadcasting.' Check the documentation: https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html to see what this does.\n",
    "        TP = 0 \n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for index in range(len(preds_class)): # We're comparing each prediction with each true value here\n",
    "\n",
    "            if preds_class[index] == 1 and true[index] == 1:\n",
    "                TP += 1\n",
    "            elif preds_class[index] == 1 and true[index] == 0:\n",
    "                FP += 1\n",
    "            elif preds_class[index] == 0 and true[index] == 0:\n",
    "                TN += 1 \n",
    "            elif preds_class[index] == 0 and true[index] == 1:\n",
    "                FN += 1\n",
    "                \n",
    "        TPR = TP/(TP + FN) # Calculating TPR and FPR and appending to our lists\n",
    "        FPR = FP/(FP + TN)\n",
    "        \n",
    "        TPRs.append(TPR)\n",
    "        FPRs.append(FPR)\n",
    "         \n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.plot(FPRs, TPRs, color=\"orange\")\n",
    "    plt.plot([0,1],[0,1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probabilities = logreg.predict_proba(X_test)\n",
    "\n",
    "roc(probas = probabilities, # pass in series of probabilities \n",
    "    true = y_test,          # pass in series of true values\n",
    "    step=0.001);            # pass in step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Suppose you're speaking with the biostatistics lead at Mayo Clinic, who asks you \"Why are unbalanced classes generally a problem? Are they a problem in this particular CKD analysis?\" How would you respond?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Unbalanced classes can be an issue because the model may have a hard time learning the minority class. In this case having balanced cases in the gridsearch does improve the model, but a 40/60 split is not a very significant difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Suppose you're speaking with a doctor at Mayo Clinic who, despite being very smart, doesn't know much about data science or statistics. How would you explain why unbalanced classes are generally a problem to this doctor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Sometimes things are complicated, and a patient has odd symptoms or a combination of problems. You may not have enough information to determine the root causes or recommed treatments because of a flood of other information. Having an abundance of knoledge that is unhelpful may fog the view for the diagnosis, and this is what happens when we have unbalanced classes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Let's create very unbalanced classes just for the sake of this example! Generate very unbalanced classes by [bootstrapping](http://stattrek.com/statistics/dictionary.aspx?definition=sampling_with_replacement) (a.k.a. random sampling with replacement) the majority class.\n",
    "\n",
    "1. The majority class are those individuals with CKD.\n",
    "2. Generate a random sample of size 200,000 of individuals who have CKD **with replacement**. (Consider setting a random seed for this part!). The [`pandas .sample()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) method may be _very_ useful here!\n",
    "3. Create a new dataframe with the original data plus this random sample of data.\n",
    "4. Now we should have a dataset with just over 200,000 observations, of which only about 0.075% are non-CKD individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    250\n",
       "0    150\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd_dummified['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_unbalanced = ckd_dummified[ckd_dummified['target'] == 1].sample(200_000, \n",
    "                                                                   replace=True,\n",
    "                                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_joined = pd.concat([ckd_dummified, ckd_unbalanced])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.999251\n",
       "0    0.000749\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd_joined['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. What do you expect will be the impact of unbalanced classes on your logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I have a feeling the accuracy is going to be great , but the specificity will not be great and we will have a lot of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Build a logistic regression model on the unbalanced class data and evaluate its performance using whatever method(s) you see fit. \n",
    "> Be sure to look at how well it performs on non-CKD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ckd_joined.drop(columns=['target'])\n",
    "y = ckd_joined['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size = 0.3,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
       "                   random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_2 = LogisticRegression(solver='liblinear',\n",
    "                             max_iter = 1000,\n",
    "                             C=10,\n",
    "                             random_state = 42, \n",
    "                             penalty = 'l2')\n",
    "logreg_2.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   54,     2],\n",
       "       [    0, 60064]], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = logreg_2.predict(X_test)\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 54\n",
      "False Positives: 2\n",
      "False Negatives: 0\n",
      "True Positives: 60064\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "print(\"True Negatives: \" + str(tn))\n",
    "print(\"False Positives: \" + str(fp))\n",
    "print(\"False Negatives: \" + str(fn))\n",
    "print(\"True Positives: \" + str(tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Do the results of your model above align with your expectations of the impact of unbalanced classes on logistic regression? If not, do you have any thoughts on why your model, considering the data, is performing how it is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I still have no false negatives so I'd say we created a pretty good model. A couple false positives but by in large this worked out great. Much rather have a couple false positives than a couple negatives.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem. (Nothing to do here...except think about it!)\n",
    "\n",
    "At this step, you would generally answer the problem! In this situation, you would likely present your model to doctors or administrators at the hospital and show how your model results in reduced false positives/false negatives. Next steps would be to find a way to roll this model and its conclusions out across the hospital so that the outcomes of patients with CKD (and without CKD!) can be improved!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
