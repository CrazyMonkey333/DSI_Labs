{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries here\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a soup object from the home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the home page soup for every restaurant\n",
    "\n",
    "Note: Your best bet is to create a list of dictionaries, one for each restaurant. Each dictionary contains the restaurant's name and path from the `href`. The result of your scrape should look something like this:\n",
    "\n",
    "```python\n",
    "restaurants = [\n",
    "    {'name': 'A&W Restaurants', 'href': 'restaurants/1.html'}, \n",
    "    {'name': \"Applebee's\", 'href': 'restaurants/2.html'},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_tags = soup.find_all('a')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = []\n",
    "for row in rest_tags:\n",
    "    restaur = {}\n",
    "    restaur['name'] = row.text\n",
    "    restaur['href'] = row.attrs['href']\n",
    "    \n",
    "    restaurants.append(restaur)\n",
    "    \n",
    "rest_df = pd.DataFrame(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'A&W Restaurants', 'href': 'restaurants/1.html'},\n",
       " {'name': \"Applebee's\", 'href': 'restaurants/2.html'},\n",
       " {'name': \"Arby's\", 'href': 'restaurants/3.html'},\n",
       " {'name': 'Atlanta Bread Company', 'href': 'restaurants/4.html'},\n",
       " {'name': \"Bojangle's Famous Chicken 'n Biscuits\",\n",
       "  'href': 'restaurants/5.html'},\n",
       " {'name': 'Buffalo Wild Wings', 'href': 'restaurants/6.html'},\n",
       " {'name': 'Burger King', 'href': 'restaurants/7.html'},\n",
       " {'name': \"Captain D's\", 'href': 'restaurants/8.html'},\n",
       " {'name': \"Carl's Jr.\", 'href': 'restaurants/9.html'},\n",
       " {'name': \"Charley's Grilled Subs\", 'href': 'restaurants/10.html'},\n",
       " {'name': 'Chick-fil-A', 'href': 'restaurants/11.html'},\n",
       " {'name': \"Chili's\", 'href': 'restaurants/12.html'},\n",
       " {'name': 'Chipotle Mexican Grill', 'href': 'restaurants/13.html'},\n",
       " {'name': \"Church's\", 'href': 'restaurants/14.html'},\n",
       " {'name': 'Corner Bakery Cafe', 'href': 'restaurants/15.html'},\n",
       " {'name': 'Dairy Queen', 'href': 'restaurants/16.html'},\n",
       " {'name': \"Denny's\", 'href': 'restaurants/17.html'},\n",
       " {'name': 'El Pollo Loco', 'href': 'restaurants/18.html'},\n",
       " {'name': 'FATZ', 'href': 'restaurants/19.html'},\n",
       " {'name': \"Fazoli's\", 'href': 'restaurants/20.html'},\n",
       " {'name': 'Five Guys Burgers and Fries', 'href': 'restaurants/21.html'},\n",
       " {'name': 'Golden Chick', 'href': 'restaurants/22.html'},\n",
       " {'name': \"Hardee's\", 'href': 'restaurants/23.html'},\n",
       " {'name': 'IHOP', 'href': 'restaurants/24.html'},\n",
       " {'name': 'In-N-Out Burger', 'href': 'restaurants/25.html'},\n",
       " {'name': 'Jack in the Box', 'href': 'restaurants/26.html'},\n",
       " {'name': 'Jimmy Johns', 'href': 'restaurants/27.html'},\n",
       " {'name': \"Joe's Crab Shack\", 'href': 'restaurants/28.html'},\n",
       " {'name': 'KFC', 'href': 'restaurants/29.html'},\n",
       " {'name': \"McDonald's\", 'href': 'restaurants/30.html'},\n",
       " {'name': \"O'Charley's\", 'href': 'restaurants/31.html'},\n",
       " {'name': 'Olive Garden', 'href': 'restaurants/32.html'},\n",
       " {'name': 'Outback Steakhouse', 'href': 'restaurants/33.html'},\n",
       " {'name': 'Panda Express', 'href': 'restaurants/34.html'},\n",
       " {'name': 'Panera Bread', 'href': 'restaurants/35.html'},\n",
       " {'name': \"Popeye's\", 'href': 'restaurants/36.html'},\n",
       " {'name': 'Quiznos', 'href': 'restaurants/37.html'},\n",
       " {'name': 'Red Robin Gourmet Burgers', 'href': 'restaurants/38.html'},\n",
       " {'name': \"Romano's Macaroni Grill\", 'href': 'restaurants/39.html'},\n",
       " {'name': 'Ruby Tuesday', 'href': 'restaurants/40.html'},\n",
       " {'name': 'Subway', 'href': 'restaurants/41.html'},\n",
       " {'name': 'Taco Bell', 'href': 'restaurants/42.html'},\n",
       " {'name': 'Taco Bueno', 'href': 'restaurants/43.html'},\n",
       " {'name': \"Wendy's\", 'href': 'restaurants/44.html'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using the `href`, scrape each restaurant's page and create a single list of food dictionaries.\n",
    "\n",
    "Your list of foods should look something like this:\n",
    "```python\n",
    "foods = [\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Note**: Remove extra white space from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods =[]\n",
    "for rest_dict in restaurants:\n",
    "    url = 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/'\n",
    "    current_soup = BeautifulSoup(\n",
    "        requests.get(f'{url}{rest_dict[\"href\"]}').content, 'lxml')\n",
    "    \n",
    "    current_rows = current_soup.find_all('tr')[1:]\n",
    "    for row in current_rows:\n",
    "        \n",
    "        \n",
    "        \n",
    "        food = {}\n",
    "        food['calories'] = row.find_all('td')[2].text\n",
    "        food['carbs'] = row.find_all('td')[4].text\n",
    "        food['category'] = row.find_all('td')[1].text\n",
    "        food['fat'] = row.find_all('td')[3].text\n",
    "        food['name'] = row.find_all('td')[0].text\n",
    "        food['restauraunt'] = rest_dict['name']\n",
    "        \n",
    "        foods.append(food)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a pandas DataFrame from your list of foods\n",
    "\n",
    "**Note**: Your DataFrame should have 5,131 rows. Please output the number of rows in your DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = pd.DataFrame(foods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5131, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows does your dataframe have?\n",
    "food_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Export to csv\n",
    "\n",
    "**Note:** Don't export the index column from your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.to_csv('./data/foods.csv'\n",
    "    ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
